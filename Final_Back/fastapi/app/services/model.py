from __future__ import annotations

from pathlib import Path
from typing import Dict, List
import numpy as np
import os

import torch
import torch.nn as nn
import torch.nn.functional as F
from PIL import Image
from torchvision import transforms, models
import cv2

from app.core.config import get_settings


BASE_DIR = Path(__file__).resolve().parent.parent.parent.parent.parent
AI_MODEL_DIR = BASE_DIR / 'AI_model'

# ==========================================
# ëª¨ë¸ ì •ì˜
# ==========================================

class DoubleConv(nn.Module):
    """(convolution => [BN] => ReLU) * 2"""
    
    def __init__(self, in_channels, out_channels, mid_channels=None):
        super().__init__()
        if not mid_channels:
            mid_channels = out_channels
        self.double_conv = nn.Sequential(
            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(mid_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        return self.double_conv(x)


class Down(nn.Module):
    """Downscaling with maxpool then double conv"""
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.maxpool_conv = nn.Sequential(
            nn.MaxPool2d(2),
            DoubleConv(in_channels, out_channels)
        )

    def forward(self, x):
        return self.maxpool_conv(x)


class Up(nn.Module):
    """Upscaling then double conv"""
    def __init__(self, in_channels, out_channels, bilinear=True):
        super().__init__()
        if bilinear:
            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)
        else:
            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)
            self.conv = DoubleConv(in_channels, out_channels)

    def forward(self, x1, x2):
        x1 = self.up(x1)
        diffY = x2.size()[2] - x1.size()[2]
        diffX = x2.size()[3] - x1.size()[3]
        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,
                        diffY // 2, diffY - diffY // 2])
        x = torch.cat([x2, x1], dim=1)
        return self.conv(x)


class OutConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(OutConv, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)

    def forward(self, x):
        return self.conv(x)


class UNet(nn.Module):
    """Standard U-Net architecture for lung segmentation"""
    def __init__(self, n_channels=3, n_classes=1, bilinear=False):
        super(UNet, self).__init__()
        self.n_channels = n_channels
        self.n_classes = n_classes
        self.bilinear = bilinear

        self.inc = DoubleConv(n_channels, 64)
        self.down1 = Down(64, 128)
        self.down2 = Down(128, 256)
        self.down3 = Down(256, 512)
        factor = 2 if bilinear else 1
        self.down4 = Down(512, 1024 // factor)
        self.up1 = Up(1024, 512 // factor, bilinear)
        self.up2 = Up(512, 256 // factor, bilinear)
        self.up3 = Up(256, 128 // factor, bilinear)
        self.up4 = Up(128, 64, bilinear)
        self.outc = OutConv(64, n_classes)

    def forward(self, x):
        x1 = self.inc(x)
        x2 = self.down1(x1)
        x3 = self.down2(x2)
        x4 = self.down3(x3)
        x5 = self.down4(x4)
        x = self.up1(x5, x4)
        x = self.up2(x, x3)
        x = self.up3(x, x2)
        x = self.up4(x, x1)
        logits = self.outc(x)
        return logits


class COVID19Classifier(nn.Module):
    """ResNet ê¸°ë°˜ COVID-19 ë¶„ë¥˜ ëª¨ë¸"""
    
    def __init__(self, num_classes=4, pretrained=False):
        super(COVID19Classifier, self).__init__()
        if pretrained:
            self.backbone = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
        else:
            self.backbone = models.resnet50(weights=None)
        num_features = self.backbone.fc.in_features
        self.backbone.fc = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(num_features, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, num_classes)
        )
    
    def forward(self, x):
        return self.backbone(x)


# ==========================================
# ì „ì—­ ë³€ìˆ˜
# ==========================================

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
_segmentation_model: UNet | None = None
_classification_model: COVID19Classifier | None = None

CLASS_NAMES = ['COVID', 'Lung_Opacity', 'Normal', 'Viral Pneumonia']

# ë¶„ë¥˜ ëª¨ë¸ìš© transform
_classification_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                        std=[0.229, 0.224, 0.225])
])

# ë¶„í•  ëª¨ë¸ìš© transform (RGB ì´ë¯¸ì§€)
_segmentation_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                        std=[0.229, 0.224, 0.225])
])


# ==========================================
# ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
# ==========================================

def load_model() -> None:
    """ë¶„í•  ëª¨ë¸ê³¼ ë¶„ë¥˜ ëª¨ë¸ì„ ë¡œë“œí•œë‹¤."""
    global _segmentation_model, _classification_model
    
    if _segmentation_model is not None and _classification_model is not None:
        return
    
    # ëª¨ë¸ ê²½ë¡œ ì„¤ì •
    seg_model_path = AI_MODEL_DIR / 'models' / 'seg_results' / 'best_model.pth'
    clf_model_path = AI_MODEL_DIR / 'models' / 'clf_results' / 'best_model.pth'
    
    # ëª¨ë¸ íŒŒì¼ì´ ì—†ìœ¼ë©´ ë‹¤ìš´ë¡œë“œ ì‹œë„ (Render ë°°í¬ í™˜ê²½)
    if not seg_model_path.exists() or not clf_model_path.exists():
        print("âš ï¸  ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. GitHub Releaseì—ì„œ ë‹¤ìš´ë¡œë“œë¥¼ ì‹œë„í•©ë‹ˆë‹¤...")
        try:
            import sys
            from pathlib import Path
            # download_models.pyê°€ ìˆëŠ” ê²½ë¡œ ì¶”ê°€
            download_script_path = Path(__file__).parent.parent.parent / 'download_models.py'
            if download_script_path.exists():
                import subprocess
                result = subprocess.run(
                    [sys.executable, str(download_script_path)],
                    capture_output=True,
                    text=True,
                    timeout=600  # 10ë¶„ íƒ€ì„ì•„ì›ƒ
                )
                if result.returncode == 0:
                    print("âœ… ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
                else:
                    print(f"âš ï¸  ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {result.stderr}")
                    raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ê³  ë‹¤ìš´ë¡œë“œë„ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {seg_model_path}")
            else:
                print(f"âš ï¸  download_models.pyë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {download_script_path}")
                raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {seg_model_path}")
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {seg_model_path}")
    
    # ë¶„í•  ëª¨ë¸ ë¡œë“œ
    if not seg_model_path.exists():
        raise FileNotFoundError(f"ë¶„í•  ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {seg_model_path}")
    
    _segmentation_model = UNet(n_channels=3, n_classes=1, bilinear=False)
    seg_checkpoint = torch.load(seg_model_path, map_location=device)
    if isinstance(seg_checkpoint, dict) and 'model_state_dict' in seg_checkpoint:
        _segmentation_model.load_state_dict(seg_checkpoint['model_state_dict'], strict=False)
    else:
        _segmentation_model.load_state_dict(seg_checkpoint, strict=False)
    _segmentation_model.to(device)
    _segmentation_model.eval()
    
    # ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ
    if not clf_model_path.exists():
        raise FileNotFoundError(f"ë¶„ë¥˜ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {clf_model_path}")
    
    _classification_model = COVID19Classifier(num_classes=4, pretrained=False)
    clf_checkpoint = torch.load(clf_model_path, map_location=device)
    if isinstance(clf_checkpoint, dict) and 'model_state_dict' in clf_checkpoint:
        _classification_model.load_state_dict(clf_checkpoint['model_state_dict'], strict=False)
    else:
        _classification_model.load_state_dict(clf_checkpoint, strict=False)
    _classification_model.to(device)
    _classification_model.eval()
    
    # ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜ í™•ì¸
    seg_params = sum(p.numel() for p in _segmentation_model.parameters())
    clf_params = sum(p.numel() for p in _classification_model.parameters())
    
    print(f'âœ… AI ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (device: {device})')
    print(f'  - ë¶„í•  ëª¨ë¸: {seg_model_path}')
    print(f'    * íŒŒë¼ë¯¸í„° ìˆ˜: {seg_params:,}ê°œ')
    print(f'  - ë¶„ë¥˜ ëª¨ë¸: {clf_model_path}')
    print(f'    * íŒŒë¼ë¯¸í„° ìˆ˜: {clf_params:,}ê°œ')
    print(f'  - ì´ íŒŒë¼ë¯¸í„° ìˆ˜: {seg_params + clf_params:,}ê°œ')
    
    # ëª¨ë¸ ê°€ì¤‘ì¹˜ ìƒ˜í”Œ í™•ì¸ (ì‹¤ì œë¡œ ë¡œë“œë˜ì—ˆëŠ”ì§€)
    seg_first_weight = next(_segmentation_model.parameters()).data[0, 0, 0, 0].item()
    clf_first_weight = next(_classification_model.parameters()).data[0, 0, 0, 0].item()
    print(f'  - ë¶„í•  ëª¨ë¸ ì²« ë²ˆì§¸ ê°€ì¤‘ì¹˜ ìƒ˜í”Œ: {seg_first_weight:.6f}')
    print(f'  - ë¶„ë¥˜ ëª¨ë¸ ì²« ë²ˆì§¸ ê°€ì¤‘ì¹˜ ìƒ˜í”Œ: {clf_first_weight:.6f}')


def unload_model() -> None:
    """ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì—ì„œ í•´ì œí•œë‹¤."""
    global _segmentation_model, _classification_model
    _segmentation_model = None
    _classification_model = None


# ==========================================
# ì „ì²˜ë¦¬ ë° ì˜ˆì¸¡ í•¨ìˆ˜
# ==========================================

def _segment_lung(image_tensor: torch.Tensor, threshold: float = 0.5) -> torch.Tensor:
    """í ì˜ì—­ì„ ë¶„í• í•œë‹¤."""
    if _segmentation_model is None:
        load_model()
    
    assert _segmentation_model is not None
    
    print(f'  ğŸ”¬ ë¶„í•  ëª¨ë¸ ì…ë ¥ shape: {image_tensor.shape}, device: {image_tensor.device}')
    with torch.no_grad():
        import time
        forward_start = time.time()
        mask_logits = _segmentation_model(image_tensor.to(device))
        forward_time = time.time() - forward_start
        print(f'  ğŸ”¬ ë¶„í•  ëª¨ë¸ forward pass ì™„ë£Œ: {forward_time:.4f}ì´ˆ')
        print(f'  ğŸ”¬ ë¶„í•  ëª¨ë¸ ì¶œë ¥ shape: {mask_logits.shape}')
        mask = torch.sigmoid(mask_logits) > threshold
        return mask.float()


def _preprocess_image(image_path: Path) -> torch.Tensor:
    """ì´ë¯¸ì§€ë¥¼ ì „ì²˜ë¦¬í•œë‹¤ (RGBë¡œ ë³€í™˜)."""
    image = Image.open(image_path).convert('RGB')
    tensor = _segmentation_transform(image).unsqueeze(0)
    return tensor

# GradCAM ìƒì„± ì „ì— ì—­ì •ê·œí™”ëœ ì´ë¯¸ì§€ ì¤€ë¹„
def _denormalize_image(tensor: torch.Tensor) -> Image.Image:
    """ì •ê·œí™”ëœ tensorë¥¼ ì›ë³¸ ì´ë¯¸ì§€ë¡œ ë³µì›"""
    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)
    
    # ì—­ì •ê·œí™”
    tensor = tensor.squeeze(0).cpu() * std + mean
    tensor = torch.clamp(tensor, 0, 1)
    
    # PIL Imageë¡œ ë³€í™˜
    return transforms.ToPILImage()(tensor)

def _preprocess_for_classification(image_path: Path, mask: torch.Tensor) -> torch.Tensor:
    """ì›ë³¸ ì´ë¯¸ì§€ì— ë§ˆìŠ¤í¬ ì ìš© í›„ ë¶„ë¥˜ìš©ìœ¼ë¡œ ì „ì²˜ë¦¬"""
    # 1. ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ (ì •ê·œí™” X)
    image = Image.open(image_path).convert('RGB')
    image = transforms.Resize((224, 224))(image)
    image_np = np.array(image).astype(np.float32) / 255.0
    
    # 2. ë§ˆìŠ¤í¬ ì ìš©
    mask_np = mask.squeeze().cpu().numpy()
    mask_3ch = np.stack([mask_np] * 3, axis=-1)
    segmented = image_np * mask_3ch
    
    # 3. PILë¡œ ë³€í™˜ í›„ ë¶„ë¥˜ìš© transform (ì •ê·œí™” í¬í•¨)
    segmented_pil = Image.fromarray((segmented * 255).astype(np.uint8))
    tensor = _classification_transform(segmented_pil).unsqueeze(0)
    return tensor


def _generate_gradcam(model: nn.Module, input_tensor: torch.Tensor, target_class: int, layer_name: str = 'layer4') -> np.ndarray:
    """Grad-CAM íˆíŠ¸ë§µì„ ìƒì„±í•œë‹¤."""
    model.eval()
    
    # Gradientë¥¼ ì €ì¥í•  hook ë“±ë¡
    gradients = []
    activations = []
    
    def backward_hook(module, grad_input, grad_output):
        gradients.append(grad_output[0])
    
    def forward_hook(module, input, output):
        activations.append(output)
    
    # ResNet50ì˜ ë§ˆì§€ë§‰ convolutional layer ì°¾ê¸°
    target_layer = None
    if hasattr(model, 'backbone'):
        # COVID19Classifierì˜ ê²½ìš° backboneì´ ResNet50
        if hasattr(model.backbone, layer_name):
            target_layer = getattr(model.backbone, layer_name)
        elif hasattr(model.backbone, 'layer4'):
            target_layer = model.backbone.layer4
    else:
        # ì§ì ‘ ì ‘ê·¼
        if hasattr(model, layer_name):
            target_layer = getattr(model, layer_name)
    
    if target_layer is None:
        print('âš ï¸ Grad-CAM: target layerë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. layer4ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
        return None
    
    # Hook ë“±ë¡
    forward_handle = target_layer.register_forward_hook(forward_hook)
    backward_handle = target_layer.register_backward_hook(backward_hook)
    
    try:
        # Forward pass
        input_tensor.requires_grad_(True)
        output = model(input_tensor)
        
        # Target classì— ëŒ€í•œ gradient ê³„ì‚°
        model.zero_grad()
        target_output = output[0, target_class]
        target_output.backward()
        
        # Gradientì™€ activation ê°€ì ¸ì˜¤ê¸°
        if len(gradients) == 0 or len(activations) == 0:
            return None
        
        grad = gradients[0]
        act = activations[0]
        
        # Gradientì˜ global average pooling
        weights = torch.mean(grad, dim=(2, 3), keepdim=True)
        
        # Weighted combination of activation maps
        cam = torch.sum(weights * act, dim=1, keepdim=True)
        cam = F.relu(cam)
        
        # Normalize
        cam = cam.squeeze().cpu().detach().numpy()
        cam = cam - cam.min()
        cam = cam / (cam.max() + 1e-8)
        
        return cam
        
    finally:
        # Hook ì œê±°
        forward_handle.remove()
        backward_handle.remove()
        input_tensor.requires_grad_(False)


def _generate_gradcam_plus(model: nn.Module, input_tensor: torch.Tensor, target_class: int, layer_name: str = 'layer4') -> np.ndarray:
    """Grad-CAM++ íˆíŠ¸ë§µì„ ìƒì„±í•œë‹¤."""
    model.eval()
    
    gradients = []
    activations = []
    
    def backward_hook(module, grad_input, grad_output):
        gradients.append(grad_output[0])
    
    def forward_hook(module, input, output):
        activations.append(output)
    
    # íƒ€ê²Ÿ ë ˆì´ì–´ ì°¾ê¸°
    target_layer = None
    if hasattr(model, 'backbone'):
        if hasattr(model.backbone, layer_name):
            target_layer = getattr(model.backbone, layer_name)
        elif hasattr(model.backbone, 'layer4'):
            target_layer = model.backbone.layer4
    else:
        if hasattr(model, layer_name):
            target_layer = getattr(model, layer_name)
    
    if target_layer is None:
        print('âš ï¸ Grad-CAM++: target layerë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
        return None
    
    forward_handle = target_layer.register_forward_hook(forward_hook)
    backward_handle = target_layer.register_backward_hook(backward_hook)
    
    try:
        input_tensor.requires_grad_(True)
        output = model(input_tensor)
        
        model.zero_grad()
        target_output = output[0, target_class]
        target_output.backward()
        
        if len(gradients) == 0 or len(activations) == 0:
            return None
        
        grad = gradients[0]
        act = activations[0]
        
        # Grad-CAM++: ì˜¬ë°”ë¥¸ alpha ê³„ì‚° ê³µì‹
        # alpha_ij^kc = (grad_ij^kc)^2 / (2 * (grad_ij^kc)^2 + sum_ab(act_ab^kc * grad_ab^kc))
        grad_squared = grad.pow(2)
        grad_sum = torch.sum(act * grad, dim=(2, 3), keepdim=True)
        alpha = grad_squared / (2 * grad_squared + grad_sum + 1e-8)
        alpha = F.relu(alpha)
        
        # Weighted combination: sum over spatial dimensions
        cam = torch.sum(alpha * F.relu(grad) * act, dim=1, keepdim=True)
        cam = F.relu(cam)
        
        cam = cam.squeeze().cpu().detach().numpy()
        cam = cam - cam.min()
        cam = cam / (cam.max() + 1e-8)
        
        return cam
        
    finally:
        forward_handle.remove()
        backward_handle.remove()
        input_tensor.requires_grad_(False)


def _generate_layercam(model: nn.Module, input_tensor: torch.Tensor, target_class: int, layer_name: str = 'layer4') -> np.ndarray:
    """Layer-CAM íˆíŠ¸ë§µì„ ìƒì„±í•œë‹¤."""
    model.eval()
    
    gradients = []
    activations = []
    
    def backward_hook(module, grad_input, grad_output):
        if grad_output[0] is not None:
            gradients.append(grad_output[0].clone())
    
    def forward_hook(module, input, output):
        activations.append(output.clone())
    
    # íƒ€ê²Ÿ ë ˆì´ì–´ ì°¾ê¸°
    target_layer = None
    if hasattr(model, 'backbone'):
        if hasattr(model.backbone, layer_name):
            target_layer = getattr(model.backbone, layer_name)
        elif hasattr(model.backbone, 'layer4'):
            target_layer = model.backbone.layer4
    else:
        if hasattr(model, layer_name):
            target_layer = getattr(model, layer_name)
    
    if target_layer is None:
        print('âš ï¸ Layer-CAM: target layerë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
        return None
    
    forward_handle = target_layer.register_forward_hook(forward_hook)
    backward_handle = target_layer.register_backward_hook(backward_hook)
    
    try:
        input_tensor.requires_grad_(True)
        output = model(input_tensor)
        
        model.zero_grad()
        target_output = output[0, target_class]
        target_output.backward(retain_graph=False)
        
        if len(gradients) == 0 or len(activations) == 0:
            print('âš ï¸ Layer-CAM: gradient ë˜ëŠ” activationì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
            return None
        
        grad = gradients[0]
        act = activations[0]
        
        # Shape í™•ì¸ ë° ë””ë²„ê¹…
        if grad.shape != act.shape:
            print(f'âš ï¸ Layer-CAM: gradient shape {grad.shape} != activation shape {act.shape}')
            # Shapeì´ ë‹¤ë¥´ë©´ activation shapeì— ë§ì¶° gradientë¥¼ ì¡°ì •
            if grad.shape[2:] != act.shape[2:]:
                grad = F.interpolate(grad, size=act.shape[2:], mode='bilinear', align_corners=False)
        
        # Layer-CAM ì•Œê³ ë¦¬ì¦˜: 
        # 1. Gradientì˜ ì–‘ìˆ˜ ë¶€ë¶„ë§Œ ì‚¬ìš© (ReLU on gradient)
        # 2. Activationì—ëŠ” ReLUë¥¼ ì ìš©í•˜ì§€ ì•ŠìŒ (ì›ë³¸ ì‚¬ìš©)
        # 3. Gradientì™€ activationì„ element-wise ê³±
        # 4. ì±„ë„ë³„ë¡œ í•©ì‚°
        # 5. ìµœì¢… ê²°ê³¼ì— ReLU ì ìš©
        
        # Gradientì—ë§Œ ReLU ì ìš© (ì–‘ìˆ˜ ë¶€ë¶„ë§Œ ì‚¬ìš©)
        grad_positive = F.relu(grad)
        
        # Activationì€ ì›ë³¸ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ReLU ì ìš©í•˜ì§€ ì•ŠìŒ)
        # Layer-CAMì€ activationì˜ ìŒìˆ˜ ê°’ë„ ì¤‘ìš”í•  ìˆ˜ ìˆìŒ
        
        # ë””ë²„ê¹…: gradientì™€ activationì˜ í†µê³„ ì •ë³´ ì¶œë ¥
        print(f'    ğŸ“Š Layer-CAM ë””ë²„ê¹…:')
        print(f'      - Gradient shape: {grad.shape}, min={grad.min().item():.6f}, max={grad.max().item():.6f}, mean={grad.mean().item():.6f}')
        print(f'      - Gradient (positive) min={grad_positive.min().item():.6f}, max={grad_positive.max().item():.6f}, mean={grad_positive.mean().item():.6f}')
        print(f'      - Activation shape: {act.shape}, min={act.min().item():.6f}, max={act.max().item():.6f}, mean={act.mean().item():.6f}')
        
        # Element-wise ê³±ì…ˆ: ReLU(gradient) * activation
        # ì´ë ‡ê²Œ í•˜ë©´ gradientê°€ ì–‘ìˆ˜ì¸ ì˜ì—­ì—ì„œë§Œ activationì´ ê°•ì¡°ë¨
        cam = grad_positive * act
        
        print(f'      - CAM (before sum) shape: {cam.shape}, min={cam.min().item():.6f}, max={cam.max().item():.6f}, mean={cam.mean().item():.6f}')
        
        # ì±„ë„ ì°¨ì›(dim=1)ì„ ë”°ë¼ í•©ì‚°í•˜ì—¬ ê³µê°„ì  íˆíŠ¸ë§µ ìƒì„±
        cam = torch.sum(cam, dim=1, keepdim=True)
        # ìµœì¢… ê²°ê³¼ì—ë§Œ ReLU ì ìš©
        cam = F.relu(cam)
        
        print(f'      - CAM (after sum) shape: {cam.shape}, min={cam.min().item():.6f}, max={cam.max().item():.6f}, mean={cam.mean().item():.6f}')
        
        # ë°°ì¹˜ ì°¨ì› ì œê±° ë° numpy ë³€í™˜
        if cam.dim() > 2:
            cam = cam.squeeze()
        if cam.dim() == 0:
            cam = cam.unsqueeze(0)
        cam = cam.cpu().detach().numpy()
        
        # ì •ê·œí™”
        cam_min = cam.min()
        cam_max = cam.max()
        if cam_max > cam_min:
            cam = (cam - cam_min) / (cam_max - cam_min + 1e-8)
        else:
            print(f'      âš ï¸ Layer-CAM: ëª¨ë“  ê°’ì´ ë™ì¼í•©ë‹ˆë‹¤ (ê°’={cam_min:.6f})')
            cam = np.ones_like(cam) * 0.5  # ì¤‘ê°„ê°’ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ íˆíŠ¸ë§µì´ ë³´ì´ë„ë¡
        
        print(f'      - CAM (normalized) min={cam.min():.6f}, max={cam.max():.6f}, mean={cam.mean():.6f}')
        
        # ìµœì†Œê°’ í™•ì¸ (ë””ë²„ê¹…)
        if cam.max() < 0.01:
            print(f'      âš ï¸ Layer-CAM: íˆíŠ¸ë§µ ê°’ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤ (max={cam.max():.6f})')
            # íˆíŠ¸ë§µì´ ë„ˆë¬´ ì‘ìœ¼ë©´ ìµœì†Œí•œì˜ ê°€ì‹œì„±ì„ ìœ„í•´ ìŠ¤ì¼€ì¼ ì¡°ì •
            cam = cam * (0.3 / (cam.max() + 1e-8))  # ìµœì†Œ 0.3ê¹Œì§€ ìŠ¤ì¼€ì¼
        
        return cam
        
    except Exception as e:
        print(f'âŒ Layer-CAM ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}')
        import traceback
        traceback.print_exc()
        return None
    finally:
        forward_handle.remove()
        backward_handle.remove()
        input_tensor.requires_grad_(False)


def _save_gradcam_image(original_image: Image.Image, gradcam: np.ndarray, mask: torch.Tensor, output_path: Path) -> Path:
    """Grad-CAM íˆíŠ¸ë§µì„ ì›ë³¸ ì´ë¯¸ì§€ì— ì˜¤ë²„ë ˆì´í•˜ì—¬ ì €ì¥í•œë‹¤."""
    # ì›ë³¸ ì´ë¯¸ì§€ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
    original_image_resized = original_image.resize((224, 224))
    img_array = np.array(original_image_resized)
    
    # Grad-CAMì„ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
    gradcam_resized = cv2.resize(gradcam, (img_array.shape[1], img_array.shape[0]))
    gradcam_resized = np.uint8(255 * gradcam_resized)
    
    # íˆíŠ¸ë§µ ìƒì„± (Jet colormap)
    heatmap = cv2.applyColorMap(gradcam_resized, cv2.COLORMAP_JET)
    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)
    
    # ì›ë³¸ ì´ë¯¸ì§€ì™€ íˆíŠ¸ë§µ ì˜¤ë²„ë ˆì´ (0.4 íˆ¬ëª…ë„), ê·¸ë ˆì´ ìŠ¤ì¼€ì¼ ì²˜ë¦¬
    if len(img_array.shape) == 2:
        img_array = cv2.cvtColor(img_array, cv2.COLOR_GRAY2RGB)

    # ë§ˆìŠ¤í¬ë¥¼ numpyë¡œ ë³€í™˜ ë° ë¦¬ì‚¬ì´ì¦ˆ
    mask_np = mask.squeeze().cpu().numpy()
    mask_resized = cv2.resize(mask_np, (224, 224), interpolation=cv2.INTER_NEAREST)
    
    overlayed = cv2.addWeighted(img_array, 0.6, heatmap, 0.4, 0)

    # ë§ˆìŠ¤í¬ ì˜ì—­ë§Œ ì˜¤ë²„ë ˆì´, ë‚˜ë¨¸ì§€ëŠ” ì›ë³¸ ìœ ì§€
    result = img_array.copy()
    mask_bool = mask_resized > 0.5
    result[mask_bool] = overlayed[mask_bool]
    
    # ì´ë¯¸ì§€ ì €ì¥
    output_path.parent.mkdir(parents=True, exist_ok=True)
    Image.fromarray(overlayed).save(output_path)
    
    return output_path


def predict(image_path: Path) -> Dict[str, object]:
    """ì´ë¯¸ì§€ë¥¼ ì˜ˆì¸¡í•œë‹¤ (ë¶„í•  â†’ ë¶„ë¥˜ íŒŒì´í”„ë¼ì¸)."""
    import time
    
    if _segmentation_model is None or _classification_model is None:
        load_model()
    
    print(f'ğŸ” ì´ë¯¸ì§€ ì˜ˆì¸¡ ì‹œì‘: {image_path}')
    
    # 1. Segmentationìš© ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ì •ê·œí™” O)
    step_start = time.time()
    image_tensor = _preprocess_image(image_path)
    print(f'  âœ“ Segmentation ì „ì²˜ë¦¬ ì™„ë£Œ: {time.time() - step_start:.2f}ì´ˆ')
    
    # 2. í ì˜ì—­ ë¶„í• 
    step_start = time.time()
    mask = _segment_lung(image_tensor)
    print(f'  âœ“ í ì˜ì—­ ë¶„í•  ì™„ë£Œ: {time.time() - step_start:.2f}ì´ˆ')
    
    # 3. ì›ë³¸ ì´ë¯¸ì§€ì— ë§ˆìŠ¤í¬ ì ìš© í›„ ë¶„ë¥˜ìš© ì „ì²˜ë¦¬ (ìˆ˜ì •!)
    step_start = time.time()
    segmented_tensor = _preprocess_for_classification(image_path, mask)  # image_path ì „ë‹¬!
    print(f'  âœ“ ë¶„ë¥˜ ì „ì²˜ë¦¬ ì™„ë£Œ: {time.time() - step_start:.2f}ì´ˆ')
    
    # 4. ë¶„ë¥˜ ì˜ˆì¸¡
    step_start = time.time()
    segmented_tensor_grad = segmented_tensor.clone().to(device)
    segmented_tensor_grad.requires_grad_(True)
    
    with torch.no_grad():
        outputs = _classification_model(segmented_tensor.to(device))
        probabilities = torch.softmax(outputs, dim=1).squeeze(0)
    
    print(f'  âœ“ ë¶„ë¥˜ ì˜ˆì¸¡ ì™„ë£Œ: {time.time() - step_start:.2f}ì´ˆ')
    
    probs = probabilities.cpu().numpy()
    top_indices = probs.argsort()[::-1][:3]
    
    findings = []
    for idx in top_indices:
        findings.append({
            'condition': CLASS_NAMES[idx],
            'probability': float(probs[idx]),
            'description': f'{CLASS_NAMES[idx]} í™•ë¥ : {probs[idx]:.2%}'
        })
    
    confidence = float(probs[top_indices[0]])
    predicted_class = CLASS_NAMES[top_indices[0]]
    predicted_class_idx = top_indices[0]
    
    # 5. GradCAM ìƒì„± (ìˆ˜ì •!)
    gradcam_relative_path = None
    gradcam_plus_relative_path = None
    layercam_relative_path = None
    
    try:
        print(f'  ğŸ¨ CAM ìƒì„± ì‹œì‘...')
        cam_start = time.time()
        
        # ì—­ì •ê·œí™”ëœ ì´ë¯¸ì§€ ì¤€ë¹„ (GradCAMì´ ë³¸ ê²ƒê³¼ ë™ì¼í•œ ì´ë¯¸ì§€)
        # segmented_tensorë¥¼ ì—­ì •ê·œí™”
        # mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
        # std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)
        # denorm_tensor = segmented_tensor.squeeze(0).cpu() * std + mean
        # denorm_tensor = torch.clamp(denorm_tensor, 0, 1)
        original_image = Image.open(image_path).convert('RGB')
        
        gradcam_base = os.getenv('GRADCAM_STORAGE_PATH', str(BASE_DIR / 'Final_Back' / 'fastapi' / 'app' / 'static'))
        static_dir = Path(gradcam_base)
        gradcam_dir = static_dir / 'gradcam'
        gradcam_dir.mkdir(parents=True, exist_ok=True)
        
        # Grad-CAM ìƒì„±
        print(f'    ğŸ“Š Grad-CAM ìƒì„± ì¤‘...')
        gradcam = _generate_gradcam(
            _classification_model,
            segmented_tensor_grad,
            target_class=predicted_class_idx,
            layer_name='layer4'
        )
        if gradcam is not None:
            gradcam_filename = f"gradcam_{image_path.stem}_{predicted_class_idx}.png"
            gradcam_path = gradcam_dir / gradcam_filename
            _save_gradcam_image(original_image, gradcam, mask, gradcam_path)
            gradcam_relative_path = f"/static/gradcam/{gradcam_filename}"
            print(f'    âœ“ Grad-CAM ìƒì„± ì™„ë£Œ')
        
        # Grad-CAM++ ìƒì„±
        print(f'    ğŸ“Š Grad-CAM++ ìƒì„± ì¤‘...')
        gradcam_plus = _generate_gradcam_plus(
            _classification_model,
            segmented_tensor_grad,
            target_class=predicted_class_idx,
            layer_name='layer4'
        )
        if gradcam_plus is not None:
            gradcam_plus_filename = f"gradcam_plus_{image_path.stem}_{predicted_class_idx}.png"
            gradcam_plus_path = gradcam_dir / gradcam_plus_filename
            _save_gradcam_image(original_image, gradcam_plus, mask, gradcam_plus_path)
            gradcam_plus_relative_path = f"/static/gradcam/{gradcam_plus_filename}"
            print(f'    âœ“ Grad-CAM++ ìƒì„± ì™„ë£Œ')
        
        # Layer-CAM ìƒì„±
        print(f'    ğŸ“Š Layer-CAM ìƒì„± ì¤‘...')
        layercam = _generate_layercam(
            _classification_model,
            segmented_tensor_grad,
            target_class=predicted_class_idx,
            layer_name='layer4'
        )
        if layercam is not None:
            layercam_filename = f"layercam_{image_path.stem}_{predicted_class_idx}.png"
            layercam_path = gradcam_dir / layercam_filename
            _save_gradcam_image(original_image, layercam, mask, layercam_path)
            layercam_relative_path = f"/static/gradcam/{layercam_filename}"
            print(f'    âœ“ Layer-CAM ìƒì„± ì™„ë£Œ')
        
        print(f'  âœ“ ëª¨ë“  CAM ìƒì„± ì™„ë£Œ: {time.time() - cam_start:.2f}ì´ˆ')
        
    except Exception as e:
        print(f'  âš ï¸ CAM ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}')
        import traceback
        traceback.print_exc()
    
    recommendations = []
    if confidence > 0.7:
        if predicted_class == 'COVID':
            recommendations.append('COVID-19 ì˜ì‹¬ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ì¦‰ì‹œ ì „ë¬¸ì˜ ìƒë‹´ ë° ì¶”ê°€ ê²€ì§„ì„ ê¶Œì¥í•©ë‹ˆë‹¤.')
        elif predicted_class == 'Viral Pneumonia':
            recommendations.append('ë°”ì´ëŸ¬ìŠ¤ì„± íë ´ ì˜ì‹¬ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤. ì „ë¬¸ì˜ ìƒë‹´ì„ ê¶Œì¥í•©ë‹ˆë‹¤.')
        else:
            recommendations.append('ì¶”ê°€ ê²€ì§„ ë° ì „ë¬¸ì˜ ìƒë‹´ì„ ê¶Œì¥í•©ë‹ˆë‹¤.')
    elif confidence < 0.3:
        recommendations.append('ì£¼ê¸°ì ì¸ ê´€ì°°ì´ í•„ìš”í•©ë‹ˆë‹¤.')
    else:
        recommendations.append('ì¶”ê°€ ê²€ì§„ì„ ê¶Œì¥í•©ë‹ˆë‹¤.')
    
    result = {
        'confidence': confidence,
        'predicted_class': predicted_class,
        'findings': findings,
        'recommendations': recommendations,
        'ai_notes': 'UNet ê¸°ë°˜ í ë¶„í•  + ResNet50 ê¸°ë°˜ COVID-19 ë¶„ë¥˜ ëª¨ë¸ ì¶”ë¡  ê²°ê³¼ì…ë‹ˆë‹¤.'
    }
    
    if gradcam_relative_path:
        result['gradcam_path'] = gradcam_relative_path
    if gradcam_plus_relative_path:
        result['gradcam_plus_path'] = gradcam_plus_relative_path
    if layercam_relative_path:
        result['layercam_path'] = layercam_relative_path
    
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        
    return result